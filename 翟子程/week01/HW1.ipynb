{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acd6629e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¤–éƒ¨åº“å¼•å…¥\n",
    "import jieba\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "767b71ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "åˆ†è¯ç»“æœ: ['æˆ‘', 'çˆ±', 'è‡ªç„¶è¯­è¨€', 'å¤„ç†']\n",
      "æˆ‘ çˆ± è‡ªç„¶è¯­è¨€ å¤„ç†\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•ä¸­æ–‡åˆ†è¯\n",
    "def chinese_tokenizer(text):\n",
    "    return jieba.lcut(text)\n",
    "\n",
    "text = \"æˆ‘çˆ±è‡ªç„¶è¯­è¨€å¤„ç†\"\n",
    "tokens = chinese_tokenizer(text)\n",
    "print(\"åˆ†è¯ç»“æœ:\", tokens)\n",
    "\n",
    "\n",
    "def chinese_word_cut(text):\n",
    "    \"\"\"å¯¹ä¸­æ–‡æ–‡æœ¬è¿›è¡Œåˆ†è¯ï¼Œè¿”å›ç©ºæ ¼åˆ†éš”çš„å­—ç¬¦ä¸²\"\"\"\n",
    "    return \" \".join(jieba.lcut(str(text)))\n",
    "\n",
    "print(chinese_word_cut(\"æˆ‘çˆ±è‡ªç„¶è¯­è¨€å¤„ç†\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b98eaddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    è‡ªå®šä¹‰é€»è¾‘å›å½’å®ç°\n",
    "'''\n",
    "\n",
    "# æ›´æ–°sigmoidå‡½æ•°ç¡®ä¿æ•°å€¼ç¨³å®š\n",
    "def sigmoid(z):\n",
    "    z = np.clip(z, -100, 100)\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self, num_classes=6, lr=0.05, epochs=5000, lambda_reg=0.1):\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.num_classes = num_classes\n",
    "        self.lambda_reg = lambda_reg  # L2æ­£åˆ™åŒ–ç³»æ•°\n",
    "        self.models = {}\n",
    "    \n",
    "    def train(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        for cls in range(self.num_classes):\n",
    "            y_binary = np.where(y == cls, 1, 0).astype(float)\n",
    "            weights = np.zeros(n_features)\n",
    "            bias = 0.0\n",
    "            \n",
    "            # æ·»åŠ æ­£åˆ™åŒ–è®­ç»ƒ\n",
    "            for epoch in range(self.epochs):\n",
    "                linear = np.dot(X, weights) + bias\n",
    "                pred = sigmoid(linear)\n",
    "                \n",
    "                # æ¢¯åº¦è®¡ç®—ï¼ˆåŠ å…¥L2æ­£åˆ™åŒ–ï¼‰\n",
    "                dw = (1/n_samples) * np.dot(X.T, (pred - y_binary)) + (self.lambda_reg/n_samples)*weights\n",
    "                db = (1/n_samples) * np.sum(pred - y_binary)\n",
    "                \n",
    "                weights -= self.lr * dw\n",
    "                bias -= self.lr * db\n",
    "                \n",
    "            self.models[cls] = (weights, bias)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        classes = list(self.models.keys())\n",
    "        probs = np.zeros((X.shape[0], self.num_classes))\n",
    "        \n",
    "        for cls, (w, b) in self.models.items():\n",
    "            linear = np.dot(X, w) + b\n",
    "            probs[:, cls] = sigmoid(linear)\n",
    "        \n",
    "        return np.argmax(probs, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bad061d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    è‡ªå®šä¹‰çº¿æ€§åˆ¤åˆ«åˆ†æï¼ˆLDAï¼‰å®ç°\n",
    "'''\n",
    "\n",
    "# çº¿æ€§åˆ¤åˆ«åˆ†æï¼ˆLDAï¼‰åˆ†ç±»å™¨\n",
    "class LDAClassifier:\n",
    "    def __init__(self):\n",
    "        self.means = {}\n",
    "        self.priors = {}\n",
    "        self.cov_inv = None\n",
    "        self.classes = []\n",
    "\n",
    "    def train(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        D = X.shape[1]\n",
    "        cov = np.zeros((D, D))\n",
    "        for cls in self.classes:\n",
    "            Xc = X[y == cls]\n",
    "            self.means[cls] = np.mean(Xc, axis=0)\n",
    "            self.priors[cls] = Xc.shape[0] / X.shape[0]\n",
    "            cov += (Xc - self.means[cls]).T @ (Xc - self.means[cls])\n",
    "        cov /= X.shape[0]\n",
    "        self.cov_inv = np.linalg.inv(cov)\n",
    "\n",
    "    def predict(self, X):\n",
    "        scores = []\n",
    "        for cls in self.classes:\n",
    "            mean = self.means[cls]\n",
    "            score = X @ self.cov_inv @ mean - 0.5 * mean.T @ self.cov_inv @ mean + np.log(self.priors[cls])\n",
    "            scores.append(score)\n",
    "        return self.classes[np.argmax(np.stack(scores, axis=1), axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "836283a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ•°æ®æ ·æœ¬ç¤ºä¾‹ï¼š\n",
      "                    text          label\n",
      "0      è¿˜æœ‰åŒé¸­å±±åˆ°æ·®é˜´çš„æ±½è½¦ç¥¨å—13å·çš„   Travel-Query\n",
      "1                ä»è¿™é‡Œæ€ä¹ˆå›å®¶   Travel-Query\n",
      "2       éšä¾¿æ’­æ”¾ä¸€é¦–ä¸“è¾‘é˜æ¥¼é‡Œçš„ä½›é‡Œçš„æ­Œ     Music-Play\n",
      "3              ç»™çœ‹ä¸€ä¸‹å¢“ç‹ä¹‹ç‹å˜›  FilmTele-Play\n",
      "4  æˆ‘æƒ³çœ‹æŒ‘æˆ˜ä¸¤æŠŠs686æ‰“çªå˜å›¢ç«çš„æ¸¸æˆè§†é¢‘     Video-Play\n",
      "ç‰¹å¾çŸ©é˜µå½¢çŠ¶ï¼š(12100, 1000)\n",
      "\n",
      "è®­ç»ƒé›†å¤§å°: 10890\n",
      "æµ‹è¯•é›†å¤§å°: 1210\n"
     ]
    }
   ],
   "source": [
    "# --- æ•°æ®å¤„ç†ä¸è®­ç»ƒ ---\n",
    "# è¯»å–æ•°æ®ï¼ˆç¡®ä¿æ–‡ä»¶è·¯å¾„æ­£ç¡®ï¼‰\n",
    "df = pd.read_csv(\"dataset.csv\", sep=\"\\t\", header=None, names=[\"text\", \"label\"])\n",
    "\n",
    "print(\"æ•°æ®æ ·æœ¬ç¤ºä¾‹ï¼š\")\n",
    "print(df.head())\n",
    "\n",
    "# é…ç½®TF-IDFå‘é‡åŒ–å™¨\n",
    "vectorizer = TfidfVectorizer(\n",
    "    tokenizer=chinese_tokenizer,\n",
    "    max_features=1000,  # é™åˆ¶ç‰¹å¾æ•°é‡\n",
    "    ngram_range=(1, 2), # åŒ…å«å•å­—å’ŒåŒå­—è¯ç»„\n",
    "    min_df=2,           # å¿½ç•¥ä½é¢‘è¯\n",
    "    max_df=0.8          # å¿½ç•¥é«˜é¢‘è¯\n",
    ")\n",
    "X = vectorizer.fit_transform(df[\"text\"])\n",
    "print(f\"ç‰¹å¾çŸ©é˜µå½¢çŠ¶ï¼š{X.shape}\")\n",
    "\n",
    "# æ ‡ç­¾ç¼–ç \n",
    "unique_classes = df[\"label\"].unique()\n",
    "label_map = {label: idx for idx, label in enumerate(unique_classes)}\n",
    "y = df[\"label\"].map(label_map).values\n",
    "\n",
    "# åˆ†å±‚åˆ†å‰²æ•°æ®é›†\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.1, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "print(\"\\nè®­ç»ƒé›†å¤§å°:\", X_train.shape[0])\n",
    "print(\"æµ‹è¯•é›†å¤§å°:\", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efdeb21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ¨¡å‹è®­ç»ƒå®Œæˆ!\n",
      "\n",
      "==== è¯„ä¼°ç»“æœ ====\n",
      "å‡†ç¡®ç‡: 0.8181818181818182\n",
      "\n",
      "åˆ†ç±»æŠ¥å‘Š:\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "         Travel-Query       0.87      0.96      0.91       122\n",
      "           Music-Play       0.78      0.85      0.82       130\n",
      "        FilmTele-Play       0.68      0.78      0.72       136\n",
      "           Video-Play       0.72      0.78      0.75       133\n",
      "         Radio-Listen       0.92      0.78      0.84       129\n",
      "HomeAppliance-Control       0.83      0.95      0.89       122\n",
      "        Weather-Query       0.84      0.87      0.85       123\n",
      "         Alarm-Update       0.89      0.94      0.91       126\n",
      "       Calendar-Query       0.89      0.92      0.90       121\n",
      "       TVProgram-Play       0.00      0.00      0.00        24\n",
      "           Audio-Play       0.00      0.00      0.00        23\n",
      "                Other       0.00      0.00      0.00        21\n",
      "\n",
      "             accuracy                           0.82      1210\n",
      "            macro avg       0.62      0.65      0.63      1210\n",
      "         weighted avg       0.78      0.82      0.80      1210\n",
      "\n",
      "\n",
      "æ··æ·†çŸ©é˜µ:\n",
      "[[117   0   1   0   1   0   1   2   0   0   0   0]\n",
      " [  0 111   7   5   0   2   2   1   2   0   0   0]\n",
      " [  3   8 106  11   1   3   2   2   0   0   0   0]\n",
      " [  1   3  14 104   2   2   4   3   0   0   0   0]\n",
      " [  0   7   8   5 100   4   1   1   3   0   0   0]\n",
      " [  2   0   1   1   0 116   2   0   0   0   0   0]\n",
      " [  5   1   1   0   0   2 107   3   4   0   0   0]\n",
      " [  3   0   1   1   0   1   1 118   1   0   0   0]\n",
      " [  2   1   2   0   0   1   4   0 111   0   0   0]\n",
      " [  0   0   5  10   1   5   1   1   1   0   0   0]\n",
      " [  0   7   7   5   2   1   0   0   1   0   0   0]\n",
      " [  1   4   4   2   2   2   3   1   2   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "# è®­ç»ƒæ¨¡å‹\n",
    "## Logistic Regression Training\n",
    "model = LogisticRegression(\n",
    "    num_classes=len(unique_classes),\n",
    "    lr=0.05,\n",
    "    epochs=5000,\n",
    "    lambda_reg=0.2\n",
    ")\n",
    "model.train(X_train.toarray(), y_train)\n",
    "print(\"æ¨¡å‹è®­ç»ƒå®Œæˆ!\")\n",
    "\n",
    "# é¢„æµ‹ä¸è¯„ä¼°\n",
    "y_pred = model.predict(X_test.toarray())\n",
    "\n",
    "print(\"\\n==== è¯„ä¼°ç»“æœ ====\")\n",
    "print(\"å‡†ç¡®ç‡:\", np.mean(y_pred == y_test))\n",
    "print(\"\\nåˆ†ç±»æŠ¥å‘Š:\")\n",
    "print(classification_report(y_test, y_pred, target_names=unique_classes))\n",
    "\n",
    "print(\"\\næ··æ·†çŸ©é˜µ:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6167d0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… ç‰¹å¾çŸ©é˜µå½¢çŠ¶: (12100, 500) (æ ·æœ¬æ•° Ã— ç‰¹å¾æ•°)\n",
      "âœ… ç±»åˆ«åˆ—è¡¨: ['Alarm-Update' 'Audio-Play' 'Calendar-Query' 'FilmTele-Play'\n",
      " 'HomeAppliance-Control' 'Music-Play' 'Other' 'Radio-Listen'\n",
      " 'TVProgram-Play' 'Travel-Query' 'Video-Play' 'Weather-Query']\n",
      "âœ… è®­ç»ƒé›†å¤§å°: 9680, æµ‹è¯•é›†å¤§å°: 2420\n",
      "\n",
      "==================================================\n",
      "ğŸ“Š æµ‹è¯•é›†é¢„æµ‹ç»“æœ\n",
      "==================================================\n",
      "çœŸå®æ ‡ç­¾: ['HomeAppliance-Control' 'Video-Play' 'HomeAppliance-Control' ...\n",
      " 'Calendar-Query' 'Travel-Query' 'Travel-Query']\n",
      "é¢„æµ‹æ ‡ç­¾: ['HomeAppliance-Control' 'Video-Play' 'HomeAppliance-Control' ...\n",
      " 'Calendar-Query' 'Travel-Query' 'Travel-Query']\n",
      "\n",
      "âœ… å‡†ç¡®ç‡: 0.8338842975206612\n",
      "\n",
      "âœ… åˆ†ç±»æŠ¥å‘Š:\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "         Alarm-Update       0.99      0.91      0.94       253\n",
      "           Audio-Play       0.56      0.67      0.61        45\n",
      "       Calendar-Query       0.99      0.93      0.96       242\n",
      "        FilmTele-Play       0.72      0.83      0.77       271\n",
      "HomeAppliance-Control       0.94      0.89      0.92       243\n",
      "           Music-Play       0.81      0.79      0.80       261\n",
      "                Other       0.15      0.53      0.24        43\n",
      "         Radio-Listen       0.96      0.77      0.85       257\n",
      "       TVProgram-Play       0.43      0.67      0.52        48\n",
      "         Travel-Query       0.94      0.91      0.93       244\n",
      "           Video-Play       0.96      0.73      0.83       267\n",
      "        Weather-Query       0.90      0.88      0.89       246\n",
      "\n",
      "             accuracy                           0.83      2420\n",
      "            macro avg       0.78      0.79      0.77      2420\n",
      "         weighted avg       0.88      0.83      0.85      2420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LDA Classifier Training\n",
    "# -----------------------------\n",
    "X_text_cut = df['text'].apply(chinese_tokenizer).apply(lambda x: \" \".join(x))\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=500,      # æ ¹æ®æ•°æ®é‡è°ƒæ•´\n",
    "    ngram_range=(1, 2),    # å•å­—è¯ + åŒå­—è¯ç»„åˆ\n",
    "    lowercase=False,       # ä¸­æ–‡ä¸éœ€è¦\n",
    "    token_pattern=r'\\S+'   # åŒ¹é…éç©ºç™½å­—ç¬¦ï¼ˆå› ä¸ºæˆ‘ä»¬å·²ç»åˆ†å¥½è¯äº†ï¼‰\n",
    ")\n",
    "\n",
    "X = vectorizer.fit_transform(X_text_cut).toarray()\n",
    "y = df['label'].values\n",
    "\n",
    "print(f\"\\nâœ… ç‰¹å¾çŸ©é˜µå½¢çŠ¶: {X.shape} (æ ·æœ¬æ•° Ã— ç‰¹å¾æ•°)\")\n",
    "\n",
    "# æ£€æŸ¥ç±»åˆ«æ•°é‡\n",
    "print(f\"âœ… ç±»åˆ«åˆ—è¡¨: {np.unique(y)}\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"âœ… è®­ç»ƒé›†å¤§å°: {X_train.shape[0]}, æµ‹è¯•é›†å¤§å°: {X_test.shape[0]}\")\n",
    "\n",
    "\n",
    "lda_clf = LDAClassifier()\n",
    "lda_clf.train(X_train, y_train)\n",
    "\n",
    "y_pred = lda_clf.predict(X_test)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ğŸ“Š æµ‹è¯•é›†é¢„æµ‹ç»“æœ\")\n",
    "print(\"=\"*50)\n",
    "print(f\"çœŸå®æ ‡ç­¾: {y_test}\")\n",
    "print(f\"é¢„æµ‹æ ‡ç­¾: {y_pred}\")\n",
    "\n",
    "print(\"\\nâœ… å‡†ç¡®ç‡:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nâœ… åˆ†ç±»æŠ¥å‘Š:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "network",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
